{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd9eb42",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-26T16:27:24.907450Z",
     "iopub.status.busy": "2023-12-26T16:27:24.906592Z",
     "iopub.status.idle": "2023-12-26T16:27:28.926445Z",
     "shell.execute_reply": "2023-12-26T16:27:28.925630Z"
    },
    "papermill": {
     "duration": 4.028304,
     "end_time": "2023-12-26T16:27:28.928861",
     "exception": false,
     "start_time": "2023-12-26T16:27:24.900557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc53376",
   "metadata": {},
   "source": [
    "Using CUDA GPU for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23b5c0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T16:27:28.939476Z",
     "iopub.status.busy": "2023-12-26T16:27:28.938671Z",
     "iopub.status.idle": "2023-12-26T16:27:29.001122Z",
     "shell.execute_reply": "2023-12-26T16:27:29.000076Z"
    },
    "papermill": {
     "duration": 0.069406,
     "end_time": "2023-12-26T16:27:29.003252",
     "exception": false,
     "start_time": "2023-12-26T16:27:28.933846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "num_labels = 24\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e3caf",
   "metadata": {},
   "source": [
    "Here I have created some functions that we'll be using for our processing and preparation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fda4ba3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T16:27:29.012604Z",
     "iopub.status.busy": "2023-12-26T16:27:29.012274Z",
     "iopub.status.idle": "2023-12-26T16:27:29.278792Z",
     "shell.execute_reply": "2023-12-26T16:27:29.277791Z"
    },
    "papermill": {
     "duration": 0.273767,
     "end_time": "2023-12-26T16:27:29.281137",
     "exception": false,
     "start_time": "2023-12-26T16:27:29.007370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage.filters import gaussian\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import exposure, util\n",
    "\n",
    "\n",
    "def horizontal_flip(img):\n",
    "    horizontal_flip_img = img[:, ::-1]\n",
    "    return addChannels(horizontal_flip_img)\n",
    "\n",
    "def vertical_flip(img):\n",
    "    vertical_flip_img = img[::-1, :]\n",
    "    return addChannels(vertical_flip_img)\n",
    "\n",
    "def addNoisy(img):\n",
    "    noise_img = util.random_noise(img)\n",
    "    return addChannels(noise_img)\n",
    "\n",
    "def contrast_stretching(img):\n",
    "    contrast_img = exposure.rescale_intensity(img)\n",
    "    return addChannels(contrast_img)\n",
    "\n",
    "def randomGaussian(img):\n",
    "    gaussian_img = gaussian(img)\n",
    "    return addChannels(gaussian_img)\n",
    "\n",
    "def grayScale(img):\n",
    "    gray_img = rgb2gray(img)\n",
    "    return addChannels(gray_img)\n",
    "\n",
    "def randomGamma(img):\n",
    "    img_gamma = exposure.adjust_gamma(img)\n",
    "    return addChannels(img_gamma)\n",
    "\n",
    "def addChannels(img):\n",
    "    return np.stack((img, img, img))\n",
    "\n",
    "def spec_to_image(spec):\n",
    "    spec = resize(spec, (224, 400))\n",
    "    eps=1e-6\n",
    "    mean = spec.mean()\n",
    "    std = spec.std()\n",
    "    spec_norm = (spec - mean) / (std + eps)\n",
    "    spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
    "    spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
    "    spec_scaled = spec_scaled.astype(np.uint8)\n",
    "    spec_scaled = np.asarray(spec_scaled)\n",
    "    return spec_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4503dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T16:27:29.291239Z",
     "iopub.status.busy": "2023-12-26T16:27:29.290485Z",
     "iopub.status.idle": "2023-12-26T16:32:37.070054Z",
     "shell.execute_reply": "2023-12-26T16:32:37.068534Z"
    },
    "papermill": {
     "duration": 307.788598,
     "end_time": "2023-12-26T16:32:37.074133",
     "exception": false,
     "start_time": "2023-12-26T16:27:29.285535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sr = 48000\n",
    "length = 10 * sr\n",
    "data = pd.read_csv(\"../input/rfcx-species-audio-detection/train_tp.csv\")\n",
    "\n",
    "fmin = sr / 2\n",
    "fmax = 0\n",
    "for i in range(0, len(data)):\n",
    "    if fmin > float(data.iloc[i]['f_min']):\n",
    "        fmin = float(data.iloc[i]['f_min'])\n",
    "    if fmax < float(data.iloc[i]['f_max']):\n",
    "        fmax = float(data.iloc[i]['f_max'])\n",
    "        \n",
    "fmin = int(fmin * 0.9)\n",
    "fmax = int(fmax * 1.1)\n",
    "\n",
    "label_list = []\n",
    "data_list = []\n",
    "audio_data = {}\n",
    "for i in range(0, len(data)):\n",
    "    recording_id = data.recording_id.values[i]\n",
    "    species_id = int(data.species_id.values[i])\n",
    "    data_list.append(recording_id)\n",
    "    label_list.append(species_id)\n",
    "\n",
    "    wav, sr = librosa.load('../input/rfcx-species-audio-detection/train/' + recording_id + '.flac', sr=None)\n",
    "    t_min = float(data.t_min.values[i]) * sr\n",
    "    t_max = float(data.t_max.values[i]) * sr\n",
    "    center = np.round((t_min + t_max) / 2)\n",
    "    beginning = center - length / 2\n",
    "    if beginning < 0:\n",
    "        beginning = 0\n",
    "    ending = beginning + length\n",
    "    if ending > len(wav):\n",
    "        ending = len(wav)\n",
    "        beginning = ending - length\n",
    "    slice = wav[int(beginning):int(ending)]\n",
    "    \n",
    "    spec=librosa.feature.melspectrogram(y=slice, sr=sr, fmin=fmin, fmax=fmax)\n",
    "    spec_db=librosa.power_to_db(spec, top_db=80)\n",
    "    \n",
    "    img = spec_to_image(spec_db)\n",
    "    \n",
    "    audio_data[recording_id] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b16bdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T16:32:37.097700Z",
     "iopub.status.busy": "2023-12-26T16:32:37.096906Z",
     "iopub.status.idle": "2023-12-26T16:32:37.120747Z",
     "shell.execute_reply": "2023-12-26T16:32:37.119612Z"
    },
    "papermill": {
     "duration": 0.04061,
     "end_time": "2023-12-26T16:32:37.123926",
     "exception": false,
     "start_time": "2023-12-26T16:32:37.083316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "learning_rate = 1e-4\n",
    "epochs = 20\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model, loss_fn, train_loader, valid_loader, epochs, optimizer, scheduler):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    for epoch in tqdm(range(1,epochs+1)):\n",
    "        model.train()\n",
    "        batch_losses=[]\n",
    "        for _, data in enumerate(train_loader):\n",
    "            x, y = data\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            loss.backward()\n",
    "            batch_losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "        train_losses.append(batch_losses)\n",
    "\n",
    "        model.eval()\n",
    "        batch_losses=[]\n",
    "        trace_y = []\n",
    "        trace_yhat = []\n",
    "        \n",
    "        for _, data in enumerate(valid_loader):\n",
    "            x, y = data\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            trace_y.append(y.cpu().detach().numpy())\n",
    "            trace_yhat.append(y_hat.cpu().detach().numpy())      \n",
    "            batch_losses.append(loss.item())\n",
    "        valid_losses.append(batch_losses)\n",
    "        trace_y = np.concatenate(trace_y)\n",
    "        trace_yhat = np.concatenate(trace_yhat)\n",
    "        accuracy = np.mean(trace_yhat.argmax(axis=1)==trace_y)\n",
    "        \n",
    "        print(\"epoch = %d, train_loss = %.5f, val_loss = %.5f, val_accuracy = %.5f\" % (epoch, np.mean(train_losses[-1]), np.mean(valid_losses[-1]), accuracy))\n",
    "\n",
    "        scheduler.step(np.mean(valid_losses[-1]))\n",
    "        if accuracy > best_acc:\n",
    "            best_acc = accuracy\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe286710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T16:32:37.142779Z",
     "iopub.status.busy": "2023-12-26T16:32:37.141675Z",
     "iopub.status.idle": "2023-12-26T16:32:37.155271Z",
     "shell.execute_reply": "2023-12-26T16:32:37.154400Z"
    },
    "papermill": {
     "duration": 0.026154,
     "end_time": "2023-12-26T16:32:37.158280",
     "exception": false,
     "start_time": "2023-12-26T16:32:37.132126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class AudioData(Dataset):\n",
    "    def __init__(self, X, y, data_type):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.augs = [addNoisy, contrast_stretching,randomGaussian,randomGamma, vertical_flip, horizontal_flip, addChannels]\n",
    "        self.data_type=data_type\n",
    "        for i in range(0, len(X)):\n",
    "            recording_id = X[i]\n",
    "            label = y[i]\n",
    "            mel_spec = audio_data[recording_id]\n",
    "            self.data.append(mel_spec)\n",
    "            self.labels.append(label)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.data_type == \"train\":\n",
    "            aug= random.choice(self.augs)\n",
    "            data = aug(self.data[idx])\n",
    "        else:\n",
    "            data = addChannels(self.data[idx])\n",
    "        return data, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f23571",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T16:32:37.177767Z",
     "iopub.status.busy": "2023-12-26T16:32:37.177144Z",
     "iopub.status.idle": "2023-12-26T16:32:37.489969Z",
     "shell.execute_reply": "2023-12-26T16:32:37.489131Z"
    },
    "papermill": {
     "duration": 0.325688,
     "end_time": "2023-12-26T16:32:37.492435",
     "exception": false,
     "start_time": "2023-12-26T16:32:37.166747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet101\n",
    "\n",
    "def get_model():\n",
    "    model = resnet101(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_labels)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee6e141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T16:32:37.503064Z",
     "iopub.status.busy": "2023-12-26T16:32:37.502234Z",
     "iopub.status.idle": "2023-12-26T16:59:18.053074Z",
     "shell.execute_reply": "2023-12-26T16:59:18.052117Z"
    },
    "papermill": {
     "duration": 1600.558671,
     "end_time": "2023-12-26T16:59:18.055505",
     "exception": false,
     "start_time": "2023-12-26T16:32:37.496834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|██████████| 171M/171M [00:00<00:00, 320MB/s]\n",
      "  5%|▌         | 1/20 [00:25<08:03, 25.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1, train_loss = 2.92614, val_loss = 2.47244, val_accuracy = 0.28289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:45<06:38, 22.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 2, train_loss = 2.40460, val_loss = 2.44471, val_accuracy = 0.35855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:05<05:59, 21.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 3, train_loss = 2.14263, val_loss = 1.91514, val_accuracy = 0.50329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:25<05:29, 20.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 4, train_loss = 1.79884, val_loss = 2.36572, val_accuracy = 0.47368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:44<05:05, 20.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5, train_loss = 1.67930, val_loss = 1.50339, val_accuracy = 0.62500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [02:04<04:42, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 6, train_loss = 1.62854, val_loss = 1.52348, val_accuracy = 0.66447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [02:24<04:20, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 7, train_loss = 1.46808, val_loss = 1.55482, val_accuracy = 0.63158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [02:44<03:59, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 8, train_loss = 1.37995, val_loss = 1.47514, val_accuracy = 0.66118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [03:04<03:39, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 9, train_loss = 1.23298, val_loss = 1.26223, val_accuracy = 0.67763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [03:24<03:19, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 10, train_loss = 1.01967, val_loss = 1.26174, val_accuracy = 0.69079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [03:43<02:58, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 11, train_loss = 0.93250, val_loss = 1.31678, val_accuracy = 0.72039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [04:03<02:38, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 12, train_loss = 0.73795, val_loss = 1.11077, val_accuracy = 0.74342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [04:23<02:18, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 13, train_loss = 0.71068, val_loss = 1.10550, val_accuracy = 0.74342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [04:43<01:58, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 14, train_loss = 0.58921, val_loss = 1.24521, val_accuracy = 0.73684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [05:03<01:39, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 15, train_loss = 0.68500, val_loss = 1.46085, val_accuracy = 0.71711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [05:22<01:19, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 16, train_loss = 0.60242, val_loss = 1.33551, val_accuracy = 0.73026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [05:42<00:59, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 17, train_loss = 0.50006, val_loss = 1.24672, val_accuracy = 0.73026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [06:02<00:39, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 18, train_loss = 0.42558, val_loss = 1.17422, val_accuracy = 0.75658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [06:22<00:19, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 19, train_loss = 0.28955, val_loss = 1.18705, val_accuracy = 0.75658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [06:42<00:00, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 20, train_loss = 0.29546, val_loss = 1.18537, val_accuracy = 0.75987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:19<06:17, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1, train_loss = 2.88450, val_loss = 2.84229, val_accuracy = 0.32566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:39<05:58, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 2, train_loss = 2.34868, val_loss = 1.79276, val_accuracy = 0.49342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:59<05:38, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 3, train_loss = 2.05625, val_loss = 1.52492, val_accuracy = 0.58882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:19<05:18, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 4, train_loss = 1.86208, val_loss = 1.69311, val_accuracy = 0.59211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:39<04:58, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5, train_loss = 1.68245, val_loss = 2.05217, val_accuracy = 0.54605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:59<04:38, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 6, train_loss = 1.60317, val_loss = 1.43755, val_accuracy = 0.64474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [02:19<04:18, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 7, train_loss = 1.30612, val_loss = 1.37936, val_accuracy = 0.65461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [02:39<03:58, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 8, train_loss = 1.15577, val_loss = 1.22019, val_accuracy = 0.68421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:59<03:38, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 9, train_loss = 1.03440, val_loss = 1.01303, val_accuracy = 0.73684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [03:18<03:18, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 10, train_loss = 0.96547, val_loss = 1.04160, val_accuracy = 0.73355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [03:38<02:58, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 11, train_loss = 0.81332, val_loss = 1.18325, val_accuracy = 0.71711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [03:58<02:39, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 12, train_loss = 0.75437, val_loss = 1.25901, val_accuracy = 0.71053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [04:18<02:19, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 13, train_loss = 0.62781, val_loss = 1.04495, val_accuracy = 0.76974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [04:38<01:59, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 14, train_loss = 0.59439, val_loss = 0.86449, val_accuracy = 0.77961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [04:58<01:39, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 15, train_loss = 0.39952, val_loss = 0.85027, val_accuracy = 0.78947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [05:18<01:19, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 16, train_loss = 0.35069, val_loss = 0.84912, val_accuracy = 0.79605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [05:38<00:59, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 17, train_loss = 0.33361, val_loss = 0.83801, val_accuracy = 0.78618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [05:58<00:39, 19.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 18, train_loss = 0.27927, val_loss = 0.83336, val_accuracy = 0.79934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [06:17<00:19, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 19, train_loss = 0.31615, val_loss = 0.84549, val_accuracy = 0.79934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [06:37<00:00, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 20, train_loss = 0.30092, val_loss = 0.84255, val_accuracy = 0.78947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:19<06:17, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1, train_loss = 2.97436, val_loss = 2.62278, val_accuracy = 0.25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:39<05:56, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 2, train_loss = 2.51350, val_loss = 1.79711, val_accuracy = 0.48355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:59<05:38, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 3, train_loss = 2.20190, val_loss = 1.45737, val_accuracy = 0.61184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:19<05:17, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 4, train_loss = 1.90110, val_loss = 1.49529, val_accuracy = 0.59211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:39<04:57, 19.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5, train_loss = 1.62556, val_loss = 2.04761, val_accuracy = 0.54934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:59<04:37, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 6, train_loss = 1.44910, val_loss = 1.22015, val_accuracy = 0.72039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [02:18<04:17, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 7, train_loss = 1.16756, val_loss = 1.28790, val_accuracy = 0.70395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [02:38<03:57, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 8, train_loss = 1.04743, val_loss = 1.20326, val_accuracy = 0.69408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:58<03:37, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 9, train_loss = 1.02714, val_loss = 1.14464, val_accuracy = 0.71711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [03:18<03:18, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 10, train_loss = 0.87603, val_loss = 1.10138, val_accuracy = 0.72697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [03:37<02:58, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 11, train_loss = 0.78406, val_loss = 1.23765, val_accuracy = 0.72039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [03:57<02:38, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 12, train_loss = 0.73023, val_loss = 1.16949, val_accuracy = 0.74342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [04:17<02:18, 19.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 13, train_loss = 0.62785, val_loss = 1.19756, val_accuracy = 0.73684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [04:37<01:58, 19.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 14, train_loss = 0.62688, val_loss = 1.13870, val_accuracy = 0.74342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [04:57<01:38, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 15, train_loss = 0.42351, val_loss = 0.91624, val_accuracy = 0.77632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [05:16<01:19, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 16, train_loss = 0.35154, val_loss = 0.95009, val_accuracy = 0.79276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [05:36<00:59, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 17, train_loss = 0.34151, val_loss = 0.90111, val_accuracy = 0.79605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [05:56<00:39, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 18, train_loss = 0.29131, val_loss = 0.93694, val_accuracy = 0.78947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [06:16<00:19, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 19, train_loss = 0.28521, val_loss = 0.91777, val_accuracy = 0.79934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [06:36<00:00, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 20, train_loss = 0.28692, val_loss = 0.90760, val_accuracy = 0.79605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:19<06:15, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1, train_loss = 2.93376, val_loss = 2.38411, val_accuracy = 0.35197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:39<05:56, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 2, train_loss = 2.42455, val_loss = 1.83946, val_accuracy = 0.50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:59<05:36, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 3, train_loss = 2.04187, val_loss = 2.08748, val_accuracy = 0.51974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:19<05:17, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 4, train_loss = 1.81673, val_loss = 1.64839, val_accuracy = 0.56579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [01:39<04:56, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5, train_loss = 1.62301, val_loss = 1.30015, val_accuracy = 0.64803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:58<04:36, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 6, train_loss = 1.24577, val_loss = 1.27454, val_accuracy = 0.71382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [02:18<04:17, 19.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 7, train_loss = 1.16050, val_loss = 1.19803, val_accuracy = 0.70724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [02:38<03:57, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 8, train_loss = 1.03111, val_loss = 1.17241, val_accuracy = 0.72039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [02:58<03:37, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 9, train_loss = 0.90109, val_loss = 1.16044, val_accuracy = 0.72697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [03:18<03:18, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 10, train_loss = 0.81624, val_loss = 1.11116, val_accuracy = 0.73026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [03:37<02:58, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 11, train_loss = 0.79097, val_loss = 1.11586, val_accuracy = 0.75658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [03:57<02:38, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 12, train_loss = 0.62296, val_loss = 1.19873, val_accuracy = 0.75658\n",
      "epoch = 13, train_loss = 0.59505, val_loss = 1.11287, val_accuracy = 0.77961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [04:37<01:58, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 14, train_loss = 0.59517, val_loss = 1.03186, val_accuracy = 0.77632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [04:57<01:39, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 15, train_loss = 0.54444, val_loss = 1.22331, val_accuracy = 0.75329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [05:16<01:19, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 16, train_loss = 0.50493, val_loss = 1.03708, val_accuracy = 0.77303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [05:36<00:59, 19.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 17, train_loss = 0.39782, val_loss = 1.24739, val_accuracy = 0.75987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [05:56<00:39, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 18, train_loss = 0.45195, val_loss = 1.12117, val_accuracy = 0.78289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [06:16<00:19, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 19, train_loss = 0.32024, val_loss = 1.11997, val_accuracy = 0.80921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [06:35<00:00, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 20, train_loss = 0.22147, val_loss = 1.06084, val_accuracy = 0.80592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fold_num = 4\n",
    "skf = KFold(n_splits=fold_num, shuffle=True, random_state=32)\n",
    "\n",
    "for fold_id, (train_index, val_index) in enumerate(skf.split(data_list, label_list)):\n",
    "    X_train = np.take(data_list, train_index)\n",
    "    y_train = np.take(label_list, train_index, axis = 0)\n",
    "    X_val = np.take(data_list, val_index)\n",
    "    y_val = np.take(label_list, val_index, axis = 0)\n",
    "\n",
    "    train_data = AudioData(X_train, y_train, \"train\")\n",
    "    valid_data = AudioData(X_val, y_val, \"valid\")\n",
    "    train_loader = DataLoader(train_data, batch_size=8, shuffle=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=8, shuffle=True, drop_last=True)\n",
    "\n",
    "    model = get_model()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "    model = train(model, loss_fn, train_loader, valid_loader, epochs, optimizer, scheduler)\n",
    "    torch.save(model.state_dict(), \"./model\" + str(fold_id) + \".pt\")\n",
    "    \n",
    "    del train_data, valid_data, train_loader, valid_loader, model, X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41d16fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T16:59:18.094135Z",
     "iopub.status.busy": "2023-12-26T16:59:18.093773Z",
     "iopub.status.idle": "2023-12-26T16:59:18.101699Z",
     "shell.execute_reply": "2023-12-26T16:59:18.100792Z"
    },
    "papermill": {
     "duration": 0.029251,
     "end_time": "2023-12-26T16:59:18.103635",
     "exception": false,
     "start_time": "2023-12-26T16:59:18.074384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_test_file(f):\n",
    "    wav, sr = librosa.load('../input/rfcx-species-audio-detection/test/' + f, sr=None)\n",
    "\n",
    "    segments = len(wav) / length\n",
    "    segments = int(np.ceil(segments))\n",
    "    \n",
    "    mel_array = []\n",
    "    \n",
    "    for i in range(0, segments):\n",
    "        if (i + 1) * length > len(wav):\n",
    "            slice = wav[len(wav) - length:len(wav)]\n",
    "        else:\n",
    "            slice = wav[i * length:(i + 1) * length]\n",
    "        \n",
    "        spec=librosa.feature.melspectrogram(y=slice, sr=sr, fmin=fmin, fmax=fmax)\n",
    "        spec_db=librosa.power_to_db(spec,top_db=80)\n",
    "\n",
    "        img = spec_to_image(spec_db)\n",
    "        mel_spec = np.stack((img, img, img))\n",
    "        mel_array.append(mel_spec)\n",
    "    \n",
    "    return mel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42be3b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T16:59:18.140864Z",
     "iopub.status.busy": "2023-12-26T16:59:18.140467Z",
     "iopub.status.idle": "2023-12-26T16:59:22.376955Z",
     "shell.execute_reply": "2023-12-26T16:59:22.375970Z"
    },
    "papermill": {
     "duration": 4.257692,
     "end_time": "2023-12-26T16:59:22.379369",
     "exception": false,
     "start_time": "2023-12-26T16:59:18.121677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "members = []\n",
    "for i in range(fold_num):\n",
    "    model = get_model()\n",
    "    model.load_state_dict(torch.load('./model'+str(i)+'.pt'))\n",
    "    model.eval()\n",
    "    members.append(model)\n",
    "    \n",
    "os.remove('./model0.pt') \n",
    "os.remove('./model1.pt')\n",
    "os.remove('./model2.pt') \n",
    "os.remove('./model3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4324cc9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-26T16:59:22.416775Z",
     "iopub.status.busy": "2023-12-26T16:59:22.416426Z",
     "iopub.status.idle": "2023-12-26T17:35:49.166383Z",
     "shell.execute_reply": "2023-12-26T17:35:49.165551Z"
    },
    "papermill": {
     "duration": 2186.771238,
     "end_time": "2023-12-26T17:35:49.168902",
     "exception": false,
     "start_time": "2023-12-26T16:59:22.397664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26/1623507928.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  data = torch.tensor(data)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('submission.csv', 'w', newline='') as csvfile:\n",
    "    submission_writer = csv.writer(csvfile, delimiter=',')\n",
    "    submission_writer.writerow(['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11',\n",
    "                               's12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'])\n",
    "    \n",
    "    test_files = os.listdir('../input/rfcx-species-audio-detection/test/')\n",
    "    print(len(test_files))\n",
    "    \n",
    "    for i in range(0, len(test_files)):\n",
    "        data = load_test_file(test_files[i])\n",
    "        data = torch.tensor(data)\n",
    "        data = data.float()\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "\n",
    "        output_list = []\n",
    "        for m in members:\n",
    "            output = m(data)\n",
    "            maxed_output = torch.max(output, dim=0)[0]\n",
    "            maxed_output = maxed_output.cpu().detach()\n",
    "            output_list.append(maxed_output)\n",
    "        avg_maxed_output = torch.mean(torch.stack(output_list), dim=0)\n",
    "        \n",
    "        file_id = str.split(test_files[i], '.')[0]\n",
    "        write_array = [file_id]\n",
    "        \n",
    "        for out in avg_maxed_output:\n",
    "            write_array.append(out.item())\n",
    "    \n",
    "        submission_writer.writerow(write_array)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1692278,
     "sourceId": 21669,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4110.27631,
   "end_time": "2023-12-26T17:35:51.892329",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-26T16:27:21.616019",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
